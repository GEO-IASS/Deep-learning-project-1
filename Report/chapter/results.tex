\chapter{Results}
\label{chp:res}

This chapters describes the result of the implemented convolutional neural network applied to the Cifar-10 dataset. It further presents the results of adjusting the hyperparameters: Learning rate, L2 Regularization and Dropouts.

First a coarse grain search is done followed by a fine grain search

\section{Coarse grain  search}
The coarse grain search is applied to identity a reasonable range for the different hyperparameters.

\subsection{Learning rate}
Based on the default learning rate of ADAM of 0.001 it was chosen to do 3 runs and investigate the loss function. The three learning rates were: 0.01, 0.001, 0.0001. The three graphs are shown in \ref{fig:lr_loss}. It can be seen that the learning rate of 0.01 is too high, while a learning rate of 0.0001 is too low. The learning rate of 0.001 was the best fit for the model of the three evaluated learning rates. Learning rates close to this value should be investigated in the fine grain search.
	
\myFigure{learningrate/loss_overview.png}{Loss function for a learning rate of 0.01, 0.001, 0.0001. Visualization from Tensorboard with some smoothing applied.}{fig:lr_loss}{1}

\FloatBarrier
\subsection{L2 Regularization}
The following evaluation of L2 Regularization will be using the learning rate of 0.001. First two different L2 regularization penalties was tested: 0.01, 0.001.  The training and validation accuracy was plottet for both as illustrated in figure \ref{fig:l2pen_1_train} and \ref{fig:l2pen_1_valid}. A penalty of 0.01 showed little overfitting and both converges around 65\% but the accuracy was quite low which implies that the regularization term was overwhelming the data loss. For 0.01 the results shows quite a difference between training and validation accuracy, which implies overfitting for the training data. 

\myFigure{l2penalty/trainAcc_1}{Training accuracy with a regularization penalty of 0.01 and 0.001. Visualization from Tensorboard with some smoothing applied.}{fig:l2pen_1_train}{1}

\myFigure{l2penalty/validAcc_1}{Validation accuracy with a regularization penalty of 0.01 and 0.001. Visualization from Tensorboard with some smoothing applied.}{fig:l2pen_1_valid}{1}

A value between these two  would therefore be preferable. A L2 Penalty of 0.005 was tested with model. This is illustrated in figure \ref{fig:l2pen_2_train} and \ref{fig:l2pen_2_valid}. This gave less overfitting but a smaller validation accuracy than with 0.001. Based on the results from 0.005 the L2 penalty was lowered to 0.0025. This is also shown in figure \ref{fig:l2pen_2_train} and \ref{fig:l2pen_2_valid}. A L2 penalty of 0.0025 gave very little overfitting and approximately the same validation accuracy as 0.001. The graph might also indicate that if more epochs were being execuated a penalty of 0.0025 would yield the highest validation accuracy.

\myFigure{l2penalty/trainAcc_2}{Training accuracy with a regularization penalty of 0.005. Visualization from Tensorboard with some smoothing applied.}{fig:l2pen_2_train}{1}

\myFigure{l2penalty/validAcc_2}{Validation accuracy with a regularization penalty of 0.005. Visualization from Tensorboard with some smoothing applied.}{fig:l2pen_2_valid}{1}



\FloatBarrier
\subsection{Dropouts}
To further achieve less overfitting dropout can also be applied. The following dropout probabilities was evaluated 0, 0,25, 0,5 and 0,75.

\section{Fine grain search}
After finding coarse values for the hyperparameters a more fine grained search was applied. This was done with a random search were all three hyperparameters was chosen randomly in some range and then run.

First a run with the parameters which were found to be most optimal in the coarse grained part. The run is instead done with 50 epochs to see if a higher validation accuracy can be achieved.


