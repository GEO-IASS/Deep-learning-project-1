\chapter{Applied theory}
\label{chp:theory}

\section{Convolutional network layers}


\subsection{Convolutional layer}

\subsection{Pooling layer}
Pooling layers are a type of layer that can be implemented in-between convolutional layers described in the section above. Their function is to down-sample the input by using a \emph{stride} and a \emph{window size} and is most often done by \emph{max pooling}. 

Max pooling works by using a filter of a specific size to choose the maximum value, and thereby down-sample. The size of the filter is determined by the window size. The stride is the step size that the filter slides over the input values with. This is illustrated in figure \ref{fig:pooling}, where the stride is set to 2 and the window size is set to 2x2. The filter then moves over the input by first choosing a maximum value inside its area, so for the red area the maximum value is 6, which is then put into the new matrix. The filter will then move two steps because of the stride and then choose a new maximum value. 

\myFigure{pooling.PNG}{Pooling layer \citep{NN3}}{fig:pooling}{0.5}

Since the pooling layer deals in down-sampling the original input, it helps control overfitting of the data. 

\subsection{Fully-connected layer}


\section{Optimization}
Optimization is closely related to the loss function, which evaluates the quality of any particular set of weights W. When doing optimization one actually tries to find weights so that the loss function is minimized. There are many different types of optimizers, however in this course the focus will be on the chosen Adam optimizer. 

\subsection{Adam optimizer}
Adaptive Moment Estimation or \emph{Adam} is a lot like RMSProp, which is a very effective adaptive learning rate method, however with the addition of momentum. In practice Adam often works slightly better than RMSProp, and according to cs231n it is currently recommended as the default \citep{NN3}. Adam also adds bias-correction, so that when a bias is added to the weights, the optimizer takes this into account. 


\section{Hyperparameters}
Hyperparameters are variables set before running one's neural network. They are inputs that can be tweaked in order to optimize the model. 


\subsection{Learning rate}
The learning rate is how quickly a network replaces old beliefs with new ones. An example could be a child learning about cars. If the first 10 cars the child sees are red, then it will believe cars are red and therefore look for red when needing to identify a car. If the child then begins seeing blue cars, then the learning rate determines how fast the child realizes that the red colour is not the most important characteristic of a car. A high learning rate results in fast realization, meaning the network will quickly change its mind. So while one would want a network that quickly can learn new characteristics, it is noteworthy that the learning rate can also be too high, which would result in fluctuating beliefs, and not make the model very precise. 

\myFigure{learning_rates.PNG}{Different learning rates \citep{NN3}}{fig:learning_rates}{0.5}

The effect of different learning rates can be seen in figure \ref{fig:learning_rates}. It is clear that the curve named \emph{good learning rate} is preferable, since it steadily approaches its minimum and flattens. The \emph{low learning rate} curve has the same tendency, however it is a lot slower and it will therefore take more time to get as good results. The \emph{high learning rate} curve reaches its minimum quickly and then flattens. However, despite initially getting a lower loss than the \emph{good learning rate} it does not reach as good a minimum in the end. The \emph{very high learning rate} curve ends up with a worse loss than it started with. This is because the parameters are bouncing around chaotically, meaning they are unable to settle in a nice spot. 

\subsection{L2 regularization}
Regularization techniques generally prevents overfitting of the training dataset. L2 regularization is one of the most common techniques. The equation for calculating L2 regularization loss for every weight in the network can be written as illustrated in (2.1). 

\begin{equation}
\dfrac{1}{2} * \lambda * \omega^2
\end{equation}

It can be read from the equation that $\omega^2$ ensures that high peaky weights are penalized heavier than diffuse weights. L2 regularization therefore encourages utilizing all inputs even though it might give the same data loss as only utilizing few inputs. Experience shows that diffuse weights yield a better result \citep{LC_cs231n}.

When using L2 regularization the calculated regularization loss is added to the data loss. It is important not to overwhelm the data loss, so that the gradient primarily comes from the regularization loss instead of the data loss.



\subsection{Dropout}
Dropout is an effective and simple regularization technique, complimenting other methods, such as the L2 regularization described in the section above. 

Dropout works by only keeping neurons active with a certain probability while training. So as shown in figure \ref{fig:dropout} the neurons are not necessarily all active. On the left side all neurons are active and connected, but on the right side seven of the neurons are deactivated causing less overfitting.  

\myFigure{dropout.PNG}{Dropout principle \citep{NN2}}{fig:dropout}{0.6}

The reason it causes less overfitting is that when the neurons used for training are varying, then the training will vary as well, meaning the model will not adapt too much to a specific belief. 



