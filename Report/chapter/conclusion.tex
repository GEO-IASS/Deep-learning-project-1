\chapter{Conclusion}
\label{chp:conc}

This report elaborates on theory related to the course \emph{Deep learning}. The theory was used for implementing two convolutional neural networks using the Tensorflow framework.

A  convolutional neural network was first developed and used for classifying images in the CIFAR-10 data set. For this network some hyperparameters were tuned and a higher accuracy was achieved. Different methods were used for tuning the hyperparamters such as graphs of the loss function, validation and training accuracy. These proved good techniques for achieving a higher accuracy on the validation set.

Further another convolutional neural network with two additional convolutional layers with ReLu activation functions were implemented. This network was deeper and more computationally expensive to run. It was trained on a stationary computer using the CPU. The training time on this computer made it infeasible to tune hyperparameters for the network, it simply took to long to train the network. The network was therefore developed and trained upon only once. Still it was possible to get a higher validation accuracy with the deeper network. So even though the amount of results for the deeper network is limited and even though there is a limit of how deep a network should be, the concept of deeper networks would seem to give a better results.

This report has presented different topics related to the concept of deep learning and focused on convolutional neural networks. Furthermore it has discussed different implementations and the tuning of hyperparameters. 